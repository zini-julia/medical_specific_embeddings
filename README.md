# medical_specific_embeddings
Model for medical specific word embeddings

Paper is available here: 

If you find our model to your research, please consider citing our paper.


# Requirements
Python >= 2.6

# Dataset
The word embedding model was trained on a subset of full-text biomedical and life sciences journal literature at the U.S. National Institutes of Health's National Library of Medicine. The dataset consisted of 28,000 documents with 8.8 million distinct sentences and 1.5 billion words.  The training approach is word2vec.
The original dataset can be found here
http://deepdive.stanford.edu/opendata

# Citation

# License

